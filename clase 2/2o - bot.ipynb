{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\joaqu\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\joaqu\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "# La última versión de spacy-stanza (>1.0) es compatible solo con spacy >=3.0\n",
    "# Nota: spacy 3.0 incorpora al pepiline nlp transformers\n",
    "!pip install -U spacy==3.1 --quiet\n",
    "!pip install -U spacy-stanza==1.0.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: 140kB [00:00, 6.67MB/s]                    \n",
      "2022-07-27 15:01:23 INFO: Downloading default packages for language: es (Spanish)...\n",
      "2022-07-27 15:01:27 INFO: File exists: C:\\Users\\joaqu\\stanza_resources\\es\\default.zip.\n",
      "2022-07-27 15:01:37 INFO: Finished downloading models and saved to C:\\Users\\joaqu\\stanza_resources.\n",
      "2022-07-27 15:01:37 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-07-27 15:01:37 INFO: Use device: gpu\n",
      "2022-07-27 15:01:37 INFO: Loading: tokenize\n",
      "2022-07-27 15:01:57 INFO: Loading: mwt\n",
      "2022-07-27 15:01:57 INFO: Loading: pos\n",
      "2022-07-27 15:01:58 INFO: Loading: lemma\n",
      "2022-07-27 15:01:59 INFO: Loading: depparse\n",
      "2022-07-27 15:02:00 INFO: Loading: ner\n",
      "2022-07-27 15:02:07 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import spacy_stanza\n",
    "\n",
    "# Vamos a usar SpaCy-Stanza. Stanza es una librería de NLP de Stanford\n",
    "# SpaCy armó un wrapper para los pipelines y modelos de Stanza\n",
    "# https://stanfordnlp.github.io/stanza/\n",
    "\n",
    "# Descargar el diccionario en español y armar el pipeline de NLP con spacy\n",
    "stanza.download(\"es\")\n",
    "nlp = spacy_stanza.load_pipeline(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata \n",
    "class bot:\n",
    "    is_train = False\n",
    "    words = []\n",
    "    classes = []\n",
    "    doc_X = []\n",
    "    doc_y = []\n",
    "\n",
    "    def preprocessing_text(self, text):\n",
    "        text=text.lower()\n",
    "        # sacar tildes de las palabras\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        # quitar caracteres especiales\n",
    "        pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "        text = re.sub(pattern, '', text)\n",
    "        pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
    "        # quitar números\n",
    "        text = re.sub(pattern, '', text)\n",
    "        # quitar caracteres de puntiación\n",
    "        text = ''.join([c for c in text if c not in string.punctuation])\n",
    "        return text\n",
    "\n",
    "    def preprocessing_example(self, text):\n",
    "        tokes = nlp(self.preprocessing_text(text))\n",
    "        print(\"tokens:\", tokes)\n",
    "        print(\"Lematización de cada token:\")\n",
    "        for token in tokes:\n",
    "            print([token, token.lemma_])\n",
    "\n",
    "    def dataset(self, dataset):\n",
    "        for intent in dataset[\"intents\"]:\n",
    "            for pattern in intent[\"patterns\"]:\n",
    "                # trasformar el patron a tokens\n",
    "                tokens = nlp(self.preprocessing_text(pattern))\n",
    "                # lematizar los tokens\n",
    "                for token in tokens:            \n",
    "                    self.words.append(token.lemma_)\n",
    "                \n",
    "                self.doc_X.append(pattern)\n",
    "                self.doc_y.append(intent[\"tag\"])\n",
    "            \n",
    "            # Agregar el tag a las clases\n",
    "            if intent[\"tag\"] not in self.classes:\n",
    "                self.classes.append(intent[\"tag\"])\n",
    "\n",
    "        # Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
    "        words = sorted(set(self.words))\n",
    "        classes = sorted(set(self.classes))\n",
    "\n",
    "    def dataset_check(self):\n",
    "        print(\"words:\", self.words)\n",
    "        print(\"classes:\", self.classes)\n",
    "        print(\"doc_X:\", self.doc_X)\n",
    "        print(\"doc_y:\", self.doc_y)\n",
    "\n",
    "    def one_hot_encoding(self):\n",
    "        # Transformar doc_X en bag of words por oneHotEncoding\n",
    "        # Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
    "\n",
    "        training = []\n",
    "        out_empty = [0] * len(self.classes)\n",
    "\n",
    "        for idx, doc in enumerate(self.doc_X):\n",
    "            # Transformar la pregunta (input) en tokens y lematizar\n",
    "            text = []\n",
    "            tokens = nlp(self.preprocessing_text(doc))\n",
    "            for token in tokens:\n",
    "                text.append(token.lemma_)\n",
    "\n",
    "            # Transformar los tokens en \"Bag of words\" (arrays de 1 y 0)\n",
    "            bow = []\n",
    "            for word in self.words:\n",
    "                bow.append(1) if word in text else bow.append(0)\n",
    "            \n",
    "            # Crear el array de salida (class output) correspondiente\n",
    "            output_row = list(out_empty)\n",
    "            output_row[self.classes.index(self.doc_y[idx])] = 1\n",
    "\n",
    "            print(\"X:\", bow, \"y:\", output_row)\n",
    "            training.append([bow, output_row])\n",
    "\n",
    "        # Mezclar los datos\n",
    "        random.shuffle(training)\n",
    "        training = np.array(training, dtype=object)\n",
    "        # Dividir en datos de entrada y salida\n",
    "        self.train_X = np.array(list(training[:, 0]))\n",
    "        self.train_y = np.array(list(training[:, 1]))\n",
    "\n",
    "    def training(self, visualization):\n",
    "        # Shape de entrada y salida\n",
    "        input_shape = (self.train_X.shape[1],)\n",
    "        output_shape = self.train_y.shape[1]\n",
    "        print(\"input:\", input_shape, \"output:\", output_shape)\n",
    "        # Entrenamiento del modelo DNN\n",
    "        # - Modelo secuencial\n",
    "        # - Con regularización\n",
    "        # - softmax y optimizador Adam\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(200, input_shape=input_shape, activation=\"relu\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Dense(100, activation=\"relu\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Dense(50, activation=\"relu\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Dense(output_shape, activation = \"softmax\"))\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=\"Adam\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "        print(self.model.summary())\n",
    "        hist = self.model.fit(x=self.train_X, y=self.train_y, epochs=200)\n",
    "\n",
    "        if visualization == True:\n",
    "            epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "            sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "            plt.show()\n",
    "\n",
    "    def save_model(self, name):\n",
    "        pickle.dump(self.words, open(name + '_words.pkl','wb'))\n",
    "        pickle.dump(self.classes, open(name + '_classes.pkl','wb'))\n",
    "        self.model.save(name + '_chatbot_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset en formato JSON que representa las posibles preguntas (patterns)\n",
    "# y las posibles respuestas por categoría (tag)\n",
    "dataset = {\"intents\": [\n",
    "             {\"tag\": \"bienvenida\",\n",
    "              \"patterns\": [\"Hola\", \"¿Cómo estás?\", \"¿Qué tal?\"],\n",
    "              \"responses\": [\"Hola!\", \"Hola, ¿Cómo estás?\"],\n",
    "             },\n",
    "             {\"tag\": \"nombre\",\n",
    "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién sos?\"],\n",
    "              \"responses\": [\"Mi nombre es TiendaPro\", \"Yo soy TiendaPro\"]\n",
    "             },\n",
    "            {\"tag\": \"contacto\",\n",
    "              \"patterns\": [\"contacto\", \"número de contacto\", \"número de teléfono\", \"número de whatsapp\", \"whatsapp\"],\n",
    "              \"responses\": [\"Podes contactarnos al siguiente <numero>\", \"Contactos al whatsapp <numero>\"]\n",
    "             },\n",
    "            {\"tag\": \"envios\",\n",
    "              \"patterns\": [\"¿Realizan envios?\", \"¿Cómo me llega el paquete?\"],\n",
    "              \"responses\": [\"Tenemos diferentes formas de envios según la zona, te recomiendo entrar a este <link>\"]\n",
    "             },\n",
    "            {\"tag\": \"precios\",\n",
    "              \"patterns\": [\"precio\", \"Me podrás pasar los precios\", \"¿Cuánto vale?\", \"¿Cuánto sale?\"],\n",
    "              \"responses\": [\"En el siguiente link podrás encontrar los precios de todos nuestros productos en stock\"]\n",
    "             },\n",
    "            {\"tag\": \"pagos\",\n",
    "              \"patterns\": [\"medios de pago\", \"tarjeta de crédito\", \"tarjetas\", \"cuotas\"],\n",
    "              \"responses\": [\"En el siguiente link podrás encontrar los beneficios y formas de pago vigentes\"]\n",
    "             },\n",
    "            {\"tag\": \"stock\",\n",
    "              \"patterns\": [\"Esto está disponible\", \"¿Tenes stock?\", \"¿Hay stock hoy?\"],\n",
    "              \"responses\": [\"Los productos publicados están en stock\"]\n",
    "             },\n",
    "            {\"tag\": \"agradecimientos\",\n",
    "              \"patterns\": [ \"Muchas gracias\", \"Gracias\"],\n",
    "              \"responses\": [\"Por nada!, cualquier otra consulta podes escribirme\"]\n",
    "             },\n",
    "             {\"tag\": \"despedida\",\n",
    "              \"patterns\": [ \"Chau\", \"Hasta luego!\"],\n",
    "              \"responses\": [\"Hasta luego!\", \"Hablamos luego!\"]\n",
    "             }\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: hola chao\n",
      "Lematización de cada token:\n",
      "[hola, 'holar']\n",
      "[chao, 'chao']\n",
      "words: ['holar', 'como', 'este', 'que', 'tal', 'cual', 'ser', 'tu', 'nombre', 'quien', 'ser', 'contacto', 'numero', 'de', 'contacto', 'numero', 'de', 'telefono', 'numero', 'de', 'whatsapp', 'whatsapp', 'realizar', 'envio', 'como', 'yo', 'llegar', 'el', 'paquete', 'precio', 'yo', 'poder', 'pasar', 'el', 'precio', 'cuanto', 'valer', 'cuanto', 'salir', 'medio', 'de', 'pago', 'tarjeta', 'de', 'credito', 'tarjeta', 'cuota', 'este', 'este', 'disponible', 'tener', 'stock', 'haber', 'stock', 'hoy', 'mucho', 'gracias', 'gracias', 'chau', 'hasta', 'luego']\n",
      "classes: ['bienvenida', 'nombre', 'contacto', 'envios', 'precios', 'pagos', 'stock', 'agradecimientos', 'despedida']\n",
      "doc_X: ['Hola', '¿Cómo estás?', '¿Qué tal?', '¿Cúal es tu nombre?', '¿Quién sos?', 'contacto', 'número de contacto', 'número de teléfono', 'número de whatsapp', 'whatsapp', '¿Realizan envios?', '¿Cómo me llega el paquete?', 'precio', 'Me podrás pasar los precios', '¿Cuánto vale?', '¿Cuánto sale?', 'medios de pago', 'tarjeta de crédito', 'tarjetas', 'cuotas', 'Esto está disponible', '¿Tenes stock?', '¿Hay stock hoy?', 'Muchas gracias', 'Gracias', 'Chau', 'Hasta luego!']\n",
      "doc_y: ['bienvenida', 'bienvenida', 'bienvenida', 'nombre', 'nombre', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'envios', 'envios', 'precios', 'precios', 'precios', 'precios', 'pagos', 'pagos', 'pagos', 'pagos', 'stock', 'stock', 'stock', 'agradecimientos', 'agradecimientos', 'despedida', 'despedida']\n",
      "X: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "input: (61,) output: 9\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 200)               12400     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 33,409\n",
      "Trainable params: 33,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1949 - accuracy: 0.1481\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2516 - accuracy: 0.1111\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1991 - accuracy: 0.1111\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1772 - accuracy: 0.0741\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1202 - accuracy: 0.1481\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.1906 - accuracy: 0.1852\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0678 - accuracy: 0.2593\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.1208 - accuracy: 0.2222\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0116 - accuracy: 0.3704\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0396 - accuracy: 0.2593\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9965 - accuracy: 0.3704\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9667 - accuracy: 0.4074\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9980 - accuracy: 0.4074\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9634 - accuracy: 0.3704\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8231 - accuracy: 0.5185\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.8424 - accuracy: 0.5185\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9464 - accuracy: 0.4444\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7662 - accuracy: 0.4815\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8423 - accuracy: 0.4444\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8731 - accuracy: 0.3704\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8445 - accuracy: 0.4444\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7242 - accuracy: 0.5185\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7715 - accuracy: 0.4815\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6963 - accuracy: 0.5185\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6633 - accuracy: 0.6296\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5562 - accuracy: 0.7037\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6232 - accuracy: 0.6296\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6078 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5768 - accuracy: 0.6296\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5822 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6245 - accuracy: 0.7407\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5650 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5228 - accuracy: 0.6296\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4970 - accuracy: 0.6296\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4723 - accuracy: 0.7778\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.7037\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4533 - accuracy: 0.6296\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3828 - accuracy: 0.7778\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4284 - accuracy: 0.7407\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3631 - accuracy: 0.7037\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2922 - accuracy: 0.8519\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2912 - accuracy: 0.8519\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2331 - accuracy: 0.7037\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.3495 - accuracy: 0.5926\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2831 - accuracy: 0.7778\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1678 - accuracy: 0.8148\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2136 - accuracy: 0.8148\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3223 - accuracy: 0.7778\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1450 - accuracy: 0.8519\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1316 - accuracy: 0.8519\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1605 - accuracy: 0.8148\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0376 - accuracy: 0.8519\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0466 - accuracy: 0.8148\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1220 - accuracy: 0.8519\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0491 - accuracy: 0.8889\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1083 - accuracy: 0.8889\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0386 - accuracy: 0.8519\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.7778\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.8519\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9439 - accuracy: 0.8889\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.8889\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.9259\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8776 - accuracy: 0.8519\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7769 - accuracy: 0.9630\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7516 - accuracy: 0.9259\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.8519\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8397 - accuracy: 0.9259\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8754 - accuracy: 0.8889\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8187 - accuracy: 0.8889\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.8889\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.9259\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7709 - accuracy: 0.8889\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.8889\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.9259\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.9630\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.9630\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.9259\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.9259\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.9259\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.9259\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.9630\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.9259\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.9630\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.9259\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.9630\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9259\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4160 - accuracy: 0.9630\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.9630\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.9630\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9630\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.9259\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.9630\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.9630\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1855 - accuracy: 0.9630\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9630\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9630\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9630\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9630\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9630\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9630\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9630\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1503 - accuracy: 0.9630\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9630\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXzb5X3v/9ele0uW5PhGie0kJCQQEpuEmxBaWCkdpQS6lnZdKaXdup61jLXdznZOu8LpWc96+vtt625/69qOH+1Yu54Bo4OtrIeWQlvGoYVBoAHshITcElvBcpxEkq176Tp/fG8kObLjJLIly5/n45FHrK++li99Zb916XNd3+urtNYIIYRY/ByNboAQQoj6kEAXQogWIYEuhBAtQgJdCCFahAS6EEK0CFejfnB3d7des2ZNo368EEIsSi+88MIxrXVPrfsaFuhr1qxhx44djfrxQgixKCmlDs90n5RchBCiRUigCyFEi5BAF0KIFtGwGnot+XyekZERMplMo5sy73w+HytXrsTtdje6KUKIFtFUgT4yMkIwGGTNmjUopRrdnHmjtWZiYoKRkRHWrl3b6OYIIVrEaUsuSql7lVIxpdTQDPcrpdSXlVL7lFIvK6UuO9vGZDIZurq6WjrMAZRSdHV1LYlPIkKIhTOXGvo3ge2z3H8jcIH573bgb8+lQa0e5pal8jyFEAvntCUXrfVTSqk1s+xyM/AP2liH91mlVIdSqldrfbRObRRLwJHjKfaNT/K2DZGq7ROTWX62f4J3bemr+X0/23eMZw9M4Pe6+E9Xr8XjKvdRSiXN3//sEPFUjs0rO3j7puUcGJ/kX3dGcSj4wBWr6A23ARBLZLj/uSMUS6Vzeh5bVnVw3cbl9u0Hdxxh5HjqrB/v6vXdXHl+Fy+PnOSJXWM199mwIsQ7N/cyciLFd3aMAPC+y1ayusvPD4aOsiuaqNo/1Obmo1evpVjSPPTiCO+/fCUA9/70IJOZQtW+F6/s4PqK40aTLbd9w+AKBvrCPH/oOG1uJ4P9YQAKxVLV8/G4HPzqm9cQ8rn4x/94nVii/p+Ot67p5JoLe9jzRpL//XJ0TvvWWz1q6P3AkYrbI+a2UwJdKXU7Ri+e1atX1+FH19fJkye57777+MQnPnFG33fTTTdx33330dHRMU8ta33//1P7eeiFUXb9zxuqPr38044j/OkP9nDZecvo72g75fv+5/d28eobSQAuXN7OL15UDtOXRk7yxe/tAiDoc/HS59/BV3+yn4deNEIvWyjx2e0XAfC/nj3Ml3+8j3P54KQ19AS9PP85ow2xRIbf/+eXAc7qcbWGx4bHeOz3ruGPH32VZw5MnPI4WoPbqXj7pgjf+D8H+ebPDgFwbDLLF949wO/+004y+ZL9fVYeb1nVwXgyy10Pv0Ik6MXjcvBHj75a1VatTz1uzfTBUmt4ZTTO3390G5/+zkv0tHv559+6CoBnDkzYz8cSbnNz1fpu/vu/GtXjej4XraE37OOZu67jLx/fw2PDY7M+/h1vXde0gV6r2TXfxrXW9wD3AGzdurW53uoxAv1rX/vaKYFeLBZxOp0zft+jjz46301reW/Es6TzRRKZAuG28syfsbjRkxoajdcM9DcSGX750n7+ZecoQ6OJqkAfMnumv/2L6/mbH+/jyIkUw9E4127oIZbIMjQar9r3wuXt/PD33nrWz+EvH9/L3/z4NQrFEi6ng6Go8fgP/uab2ba284wf7y9+uIevPbmfdK7IcDTObVeu5o/ee3HVPt97Ocqn7vs5r41NMhyNc/l5y3A7FUPRBPvHp8jkS/zVB7bw3kuNXngskWHbH/2IodE448ms8dxHE/Ynm52fv54OvweA+597nbsefqXquH3zo9vO+vjU2395cCf/57VjJDJ5Dk+kGE9mKZY0TodiaNR47Xd+/nrCbW4u++LjDI0mCJm/W4/+zlvY1BeqW1u+/tQB/t9HdzMxmWVoNMEvbe7lK7ed9XDiWavHPPQRYFXF7ZXA7J83mtSdd97J/v37ueSSS7jiiit429vexm233cbFFxt/RO95z3u4/PLLGRgY4J577rG/b82aNRw7doxDhw6xceNGPv7xjzMwMMA73vEO0ul0o57OojKezFT9b4mZoTM8rWwAkC0UOZnKs6Y7wNquAMPReNX9w6NxOvxurt9khPyLr5/gtdgkg31hBvtDDEcTWFfsGhqNM9gXPqfn0BP0ojVMTOXMn2+0+WyDY6AvTLGkeWL3GIlMoWb7rG2vjMbZFU0w2BdisC/Mq0cTvDRysmofgEjIR0/Qy3A0Yb/hDUfjDEfjrFzWZod55fdVHrdmMtgXZjyZ5ck94wCkckUOHpsCqHo+SikG+8MMHzWOkcfp4ILl7XVty0C/8Rr/dP8EoyfTdulnodWjh/4I8Cml1APAlUC8HvXzL/zb8Cm1v3O1qS/E/3jXwIz3/8mf/AlDQ0Ps3LmTJ598kne+850MDQ3ZUwvvvfdeOjs7SafTXHHFFbzvfe+jq6ur6jFee+017r//fr7+9a9zyy238NBDD/HhD3+4rs+jFVm9xVgyy/pI8JTtw6PxU77n2KQRnJGgl019IX7++smq+4ejCQb6QmxYEcTlUDz84ijFkmawP0Qs6eXBHSO8kcjgdChiySwD5/hHGAl67TYvD/kYisZZ2x2g3Xt2f2YD5hvBgzuMiuZg/6lvDKs7/QS9Lh595ShTuSIDfWHcLkW2UOLfXoriczs4v6f9lMet7KEPR40e+vTAvnBFe9VxG6hjj7YerND8zo5yxXc4Gmd9pN1+7S0DfWH+7ukD+D0uNqwI4nbW95zKgd7qtjTqzW8u0xbvB54BNiilRpRSv6GUukMpdYe5y6PAAWAf8HXgzArQTWzbtm1V88S//OUvs2XLFt70pjdx5MgRXnvttVO+Z+3atVxyySUAXH755Rw6dGihmrtoaa0ZnzTCxQoZy2w9dGtgKxLyMtgfZvRkmpMpI+TzxRJ73kgy2BfG63JywfIgT+87Bhh/3NYf+9Bown7scw0sK9Bj5qeM6aFyplYuayPc5ubpfcdwOhQXLg+eso/DodjYFyo/t/6QHSZP7zvGxt4QTkd1VXSwL8yesSQTUzn6O9oYPZnm4LGpU9o6/bg1qtc5k429xvF4et8xutuNcYDhaIJkJs/BY1NVoTrQFyJf1Dx/6HjNN8ZzFfa7WdXZVvE71pg3v7nMcvngae7XwCfr1iLTbD3phRIIBOyvn3zySZ544gmeeeYZ/H4/1157bc155F6v1/7a6XRKyWUOTqTy5ItG6SOWKAe61ppYMoPP7eCNRIZjk1m628vH1wr7SNBn97iGowmuXt/Na2OT5Iolu9wx0Bdi99EEIZ+Llcva6Gr3oJTRo7O+91xrqpGQz34OJ1M5Rk6k+dCV55314ymlGOgL8bP9E1ywvB2fu/Y4zmBfmOcOHsftVFwQCeJ0KHxuB5l8qWZPcaAvZA+O3rJ1FX/1xF7jcWoE9uC049ZMgj43a7sDHDw2xeaVYY5NZhmOxtl91BgkH6gIbuu5aQ2b5qn3PNAb5sjxNP0dbSwLeE7/DfNA1nKpEAwGSSaTNe+Lx+MsW7YMv9/Pq6++yrPPPrvArWtdsYq6eeXXyWyBTL7EVeu6gVN76eVA9zJg/pFadXRrQNL6Qx60gz2MUgq/x8X53QGGRhMMjcY5r8tPyHduyzB0t3vsdlnlwnPtDVrtH5glhKze4IYVQTwuB06HYmNvqOq+Wo+pFLzv8v5THqfWY1vHrdlYb8KDfSEG+sL262lsKx+z8zr9dulrcJ56z9ZrXc/B1jMlgV6hq6uLq6++msHBQT7zmc9U3bd9+3YKhQKbN2/mD/7gD3jTm97UoFY23gPPvc6+2ORZf3+hWOJLP3iVux5+hQd3HKkqs9T6+toNxvQu6w/1ey9HeeHwCcaTWZSCzoCHzoCH/o42e3bDrmiCgMfJ2i7jU5ZVHx+c1mt77uAEzxyYqEvN0+ty0uF3M57M2m8oswXxXFiBOtsbgx36vdUlhsr7Kq1c1kbI52Jtd4CVy/z0d7TRE/TanzBqPnaT1c8t1uu2ySyjxdN5vv3sYbrbq5+Pw6HY1BvCoeCiFfPzXKzXupGDx021lkszuO+++2pu93q9fP/73695n1Un7+7uZmiovELCpz/96bq3r9FKJc1d//IKt1y+ii/9yuazeoyfHznJ3z65H4/TwXd3jvKFdxvlta6Ax+51Q7n8sr6nnVWdbewyZ6Xc9fArXLKqwyidBLy4Kkomdg99NM7G3hAOs3482Bdm25pOtg+usB//xsEVPHtgAqBq+7mIBL3EkhkSmTx9YR+d5/jR+83rutiyquOUE64qresJ8JYLurlpc6+97abBXvbHpmrW3ZVSfOCKVfaMll+5fCWFGU6oGuwPs21tZ92OT729fWOEx4bf4Mq1nSQyeVZ3+pnMFnjvpaeeiPaeS/tZ3eWnzTPzFORzcdl5y7hsdYc9q6oRJNDFGUlmCmgNw0dPnXUyV1ZP+3euW8+f/3Avzx86Dhi96OjJ8piDVX6JhLwM9oUZisZ5/XiKZKZgzMxwOuyBSDBC+4ndYyQzeXYdTXDL1vJs2jaPkwfveHNVO7YP9rJ9sJd6igR9xJJZEun8Oc+asR7vu5+8etZ9XE4H3/6NK6u2XbW+m6vWd8/4PZ975yb769+7/sIZ9/O5nTz4m2+e8f5Gu2B5kH81j8+ygIenfv9tM+5725Wrue3K+TuhMdzm5uFPzP5azTcpuYgzksjkAdj7xiT54tmdJj8cTdDd7uFtFxm9zp/sGSfgcbKmy191SrZVculp9zHYH+bwRMruUR+fyvHyaJxIqBzo1mDf94feIJUrNqSWGQl6eX0ixYEas0aEmG9NF+i6ydaKmC+L9XnG00ag54olXhs7uzr60Gicgb4wFy4P4nE6GE9miYR8RIJeEpkCmXwRMAYXPS4HoTaXHc7WWiVgBH5PxawXq9774PONmwvcE/QyMZVD68bWUsXS1FSB7vP5mJiYWLRhN1fWeug+36mDUM3OCnQozyQ5E5l8kX2xSQb6QridDjasMGq8PUEvPRUn5lj/R4Je40w/Mxx3HD7Bmi6/vU5GZQ99echLV8DDjsMn5uVswLnoqSgBDczDfGchZtNUNfSVK1cyMjLC+Ph4o5sy76wrFi02iYpAP5szefeOJSmUdNXsiVdG40SCXiJBcx53MsuqTj+xZMYOyJ6g1xxwzLJ1TScup4N9sUn7e8Cct90f5qm94/NyNuBcWDMrugIeVtSYNSLEfGqqQHe73XIFnyZn9dCNKYJn3kO35pJbPe6B/jA8f4RI0FfRQzfq6LFElvN7yid3DfaH+fGrMfOsv5IZ6N6qxx/oC/HU3vGG1a+t9mzqCzXlvG3R2pqq5CKak9aaP39sD3vHkvag6JvXdbHraIJiSTNyIsX/871dFKYNksZTeT7/3SEms+U1todG4wR9LlZ1GmcdWid5GPOgjTD86x/t42Pf2sHh46mqHvhgxdxq6w2hsuRi7FPxRtEAVqA322nyYmmQQBen9frxFF/5yT7+7aUo8XQep0OxZWWYVK7Iscksjw2P8Y2nD9qr91ke3z3GPzxzmH/fUy6hWeubWL3Xgb4w79rSx7UbeugOeNk+sAIFRE+muXB5O9dtLM+/fufmPm4cXMHF/WG2D67gHZuWn3KSyNXru3j7xghv3zjzvO35tKrTzy9t7uVdm2tfkEOI+dRUJRfRnKwyyXgyi9vpIORz2bXi8WS2YjGqOJes6qj4vrj9/zs391Iolth9NMGH31Re38TjcvA3H7zUvn33r14+Yzs2rAjytx827l/V6eeeX9t6yj4dfg/f+MgVZ/tUz5nb6WjIOthCgAS6mAOrVh5LZmn3ugi1uatWFqy8UEIlaz1wq+d+4NgU2UJpXla7E0JIoIs5sAI5lsxQLHkJt7mrVhYsr6tdHiQtlXS5hz4aR2ttvzGc6/omQojapIYuZqW1ti8uEUtkSWTyhHxue2XB8WTWXnPl1TeS9tmjh4+nmMoV2dQbYmIqx1giy3A0YVxwoTtQ+4cJIc6JBLqY1Vgiy8RUjnCbm4mpHCdTecJtbntlwZhZQw+3uckVSvYqjFZv/ANXGOupDEfjDI3GuWhFyF5MSwhRX/KXJWZllU3eemEPxZLmyPEUoTajUhcJehk9meZEKs9bzSuYD9vXqUzgdipuvqQPpSqueSn1cyHmjdTQl7B7nz7Id1+K4nM5+MsPXEJ/R/mKNLlCiU/e9yK7ogmUMgL9kZeiFEravnJ6T9DL7qNGgF95fieP7xrjzx/bw7efPczhCWPp1g6/h7VdAf7+p4dIZgtSPxdiHkkPfQn71jOHiJ5M8x8Hj/PknljVfbuOJnh81xjd7R4+ce061lTUva0r+0SCPo7GjSmLK0I+fue6C9iwIkhHm5stKzu4/ZrzAbjj2nVcsqqDGwaWc91FjZkfLsRSID30JSqeznN4IsVnbtjAPU8dOGXKoVUD/8ptl7Gq08+R4yn7vnCbFejlszR7gl6u27ic37p23Sk/65atq6rWJhdCzA/poS9RuyqudD9QcaUfy3A0TrjNbV8YuHIVwXBFycVSeYq+EKIxJNCXqOGKa14O9oerphwa91efou9zOwn5jA90oWmBrlT5AslCiMaRQF+ihqMJloeMNcgH+kJVUw7zxRKvHk2essCUdTJRueRSXipWpiIK0XjyV7hEDUfj9owT639ryuG+2CS5YumUJWitmrnVU7dWOuyRcosQTUECfQlK54yrBlnL0a7tDtDmdtoDoTOdom+VWKbX0HumrUkuhGgMmeWyCCQzeW6951lOpvJcvb6LP/2VLaf9nt++/+e8ePgE3e0e7r/9TURPpvlvDw/x9V/byoFjk5Q0bDID2+lQbOwN2gOlw9EEbW4na6edom/10IPmtMWg14XP7TjlIhNCiMaQQF8EXj+eskP2x6+e/vJ8pZLm+68cpavdw0sjcV4eifPi6yd47tBxnjt0nDcSxtzxyrM213QHeHb/BAAjJ9Kc1+XH6ai+4s6t21azuiuAx2V8sFNK8cWbB9nYK2d/CtEMpOSyCKRyRQDO6/KTyhVOszecSOUolDTvv9xaRyVRcUp+nF3mlMTKM0MjQR/jk1m01oxXXMuz0rqedn61Yi1zgPdvXSVX5xGiSUigLwLWJdwiIR+pXJFSSc+6f8xcznZTX4hI0MvwaNxeMXFoNMHQqLGmSuU1LyNBL/mi5kQqTyyZlXnlQixCEuiLQCpr9NB72o1ecypfnHV/K9B7gl4G+8P8x8HjHJowzvR8eeQke95IzjjgOZbIcGwyKwOdQixCEuiLwFTO6qEbITuVnb3sYl1wIhL0MtgXYvRkGoCr1nURS2ZnnZL4WmySfFHLQKcQi5AE+iJgBbgVsqcLdOsanz1Brz2TBcprk8OpUxKtk4as0oz15iGEWDwk0BcBa1DUqmtbt2cSSxjX/vR7XPZMlp6gl2svNFY69HtmnpJoDZ5KDV2IxUemLS4CU9kCbqdimd+Y/z05rYf+8Isj3PXwKwB88T2DjCezdkD3d7TR4Xcz0Bci7HezqrONSNB3ypTEgNeF3+O013iRGroQi8+cAl0ptR34a8AJfENr/SfT7g8D/wtYbT7mn2ut/77ObV2yprIF/B4Xfq/xck2fuvij3THavS6UUvx4d4zjU7mKhbMUf33rpXbA/+n7tuD3OGv+nEjQaw+eSg1diMXntIGulHICXwWuB0aA55VSj2itd1Xs9klgl9b6XUqpHmCPUuoftda5eWn1EjOVKxLwOAmYQTyZrS65DEfjbFvbicOheOnISVwOxcUrO+z7rcvDAbx5XdeMPycS9HFoImX8LK98eBNisZlLDX0bsE9rfcAM6AeAm6fto4GgMiY2twPHgdOfASPmZCpbIOB12SGbqii5JDJ5Dk2kGOgLMdgXZuREmtGTaXuK45noMQdCrQFSIcTiMpduWD9wpOL2CHDltH2+AjwCRIEg8AGtdWnaPiilbgduB1i9evXZtHdJmsoV8XtdBDwu+7Zlt3Whiv4wTvNEoXxRn9UslYgstiXEojaXHrqqsW36qYo3ADuBPuAS4CtKqVMW+NBa36O13qq13trT0zP9bjGDVLZAwOPE7zVKLpXTFoemXXnIcjY1cFk9UYjFbS6BPgJUXhByJUZPvNJHgYe1YR9wELioPk0Uk2bJxe104HE57BONwKifR4JeIkEfXe1eesNGueRsQtmaqigDokIsTnMJ9OeBC5RSa5VSHuBWjPJKpdeB6wCUUsuBDcCBejZ0qdG6/CEoZQ6KAgQ8TnspAIDh0URVz9w6Yehs5pFbQS5z0IVYnE4b6FrrAvAp4DFgN/Cg1npYKXWHUuoOc7cvAlcppV4BfgR8Vmt9bL4a3Up2HjnJ5j98zD67E+D3//kl/vMDO+3bqVzBHhANeF12ySVXKLFvfJJNFYF+cX8YpWD5WdTQ+zp8Vf8LIRaXOc1N01o/Cjw6bdvdFV9HgXfUt2lLw77YJIlMgX2xSbtnvGdskkPHptBao5SySy4AAY/LLrmkcgWKJU13xYyWj/7CGi5d3UGH/8wv2rw+EuTrv7aVay7srsMzE0IsNDn1v8Gs3ra1oJa1LZ7OM3IiTbGkyeRL9slAfq+TKbPkkjZXXWxzl08UCvncXHPh2Q84X79pOV5X7ROPhBDNTQK9wazedmWgW/PMh6MJ+6zQdrOH3u4t99DT5vRFn1sCWAghgd5w1gBnrLKHbgb1cDRu98b95hx0f8WgqNVDl0AXQoAEesNZC23FzOt8aq3tMsxwNGH3xgPmHPSA12V/T8YqucywNosQYmmRQG8wq6Ri9dBzxRIF8xJzQ6NxO9yts0QDHpf9PemccTJum/TQhRBIoC+YUkmfsuwtYJdUrBq6VU5Z1dlGLJm1Vz+0zhKtHBTN1BgUFUIsXRLoC+Thn49y1R//yA5hy9S0HroV+tvWGKsiPn/wOFAxKOpxkSuWyBVK5VkuHnkZhRAS6Atm71iSRKbAG/FM1XarRx5P58nki/bViK5YswyA58xAtwdFzWBP54oyKCqEqCKBvkCsQc/K2SxQffWh8WTW7rEvD/s4r8vPnrEkUO6h22ui5wpSchFCVJFAXyBWkFee4g/GoGjQZ4T1+GTWHgRt97oYrLiQs79ilgsYc9Wteegyy0UIARLoC8Ya9IwlpvfQi5xvXrA5lshWzDt3Vq3R4ndbgW5dtahQLrnImZ1CCCTQF4zVQx+frA70VK7AGjPQx5OZqjNDB/uNHrrP7cDlNF4qa/piyqyhe10OHI5aS9YLIZYaCfQFkMkXiafzQHUPvVTSpHJFVnf6cSgj9K2Si9/jspfFtUIcyiWXqWyBTK4oA6JCCJsEeh0dOZ6iWJp+MSc4VtErr6yhp8ySSdDnojPgNQdFjW0Br5Pudi8rQj67fg7Yi3RN5YySiwyICiEsEuh1cnwqx3V/8e888tLoKfdZ5Ravy1FzEa6A10Uk6CWWzJLKFlCqPHPl8jXLWFFx0WZrtstktkg6X5IBUSGEbU7roYvTi55MkyuWODg+dcp9Vpnlot4QI8dT9na7N+5xEQl5iSUzTGYDBDwulHnB5z/+5YspFMu9/lCbG4BEOk9aSi5CiArSQ68Tq5QyfdATjMFOMC7kPDGVI1801mAp18udRg89kTWvTlS9vnlnoHyxCp/bicflIJExTkRqc8tLKIQwSBrUidULnz4tEYwpiw4FG1cEgXJNvXLOeSToY2IqRzJTqBoErSXkc5MwzyyVkosQwiKBXiflE4dODfRYMktXu5cV4Tbjthn61lmhfq+LnqCXYklz5ESqahC0lnCbi0RaBkWFENUk0OvEKrlMPxPU2JYlEvQSCXrt21BeaTFgllwADh6bOn0Pvc1NIpMnnZcauhCiTAK9TqzZK8cmc5SmTV0cT2bpCXqJhLxV+6ZyFbNczPuSmfIFoWcSbnMbi3nlpIcuhCiTQK8Tq9ddLGmOp3IMjcbttVZiyQyRoJfudi9KlXvxk9mKWS7B8tTE0wW6VUNPSw1dCFFBAr1OYomsfdLP3rEk7/nqT7n3pwfJ5Iscm8yxItyG2+mgu93L6Ik0UJ6H7vc66TFLLlBeUXEmVg9dSi5CiEoS6HWgtWY8mWVTr3Gq/pN7ximUNDuPnGTvWJJiSdszXC5aEWTX0QRgLIHrcTlwOx343E571UX/aWvoLhKZApl8SQJdCGGTQK+DRLpArliy1175yasxAIZH4wyNGuFtLbQ10Bdm71iSXKFEKlus6o1bA6Ptp53l4raXGJAauhDCIoFeBzH7xCEjtF+LTQIQjWd4et84IZ+LlcuMKYuD/SHyRc3esSRTuUJVb9yqo/vnUEO3yIlFQgiLpEEdWAOiq7v8BM0wXuY3QvfxXWMM9IXtU/mt0B+OxpnKFuy1WQB7pstcZrlYZFBUCGGRQK8Dq4ceCXrpMUP5PZf2A5AvarsUA3Bep592r4uh0QSpXLHqJCKr5HK6QdFQRaBLDV0IYZFArwNrXnkk5LND+ep13fR3GGWWgf5yoDscik29IYajcSan9dCtmS6nGxSt6qFLoAshTBLodRBLZGlzOwl4nPSYdfDB/jCDZpBXXhsUjIDfdTRB9GTanuoI5Rp6+5nU0KXkIoQwSaDXwbHJLN1BD0optqwMc9GKIMtDXq65sIdVnW2c39Netf9V67rJ5EuMJbJV9w30hQh6XZzX5Z/150kPXQhRi6yHXgeJTIGONmOJ24+95Xw+9pbzAfjQlefxoSvPO2X/6zctZ/gLN1AoaUK+8ktwwfIgr3zhhtP+vPaK75EauhDCIoFeB/F0nlDbmR3K081kmY3ToQj6XCQzBSm5CCFscyq5KKW2K6X2KKX2KaXunGGfa5VSO5VSw0qpf69vM5tbIp2vKoMsBKuOLj10IYTltIGulHICXwVuBDYBH1RKbZq2TwfwNeDdWusB4P3z0NamFU/nqwYqF4L1BiI1dCGEZS499G3APq31Aa11DngAuHnaPrcBD2utXwfQWsfq28zmlsg0oIdulngk0IUQlrkEej9wpOL2iLmt0oXAMqXUk0qpF5RSv1avBja7bKFIJl+qOvl57vAAABI8SURBVNlnIVhvIF6XTFQSQhjmMjKnamzT0267gMuB64A24Bml1LNa671VD6TU7cDtAKtXrz7z1jahRNpYArcRge5zO3A4ar08QoilaC6BPgKsqri9EojW2OeY1noKmFJKPQVsAaoCXWt9D3APwNatW6e/KSxK8XQeoGr64ULYuqaTicncgv5MIURzm8vn9eeBC5RSa5VSHuBW4JFp+3wXeItSyqWU8gNXArvr29TmlMgYgb7QNfRbtq7i7379igX9mUKI5nbabqXWuqCU+hTwGOAE7tVaDyul7jDvv1trvVsp9QPgZaAEfENrPTSfDW8Wdg99gQNdCCGmm1OdQGv9KPDotG13T7v9Z8Cf1a9pi0Mi3ZgeuhBCTCdTJM5Rwq6hS6ALIRpLAv0cJTLWLBdZRUEI0VgS6Ocons7jczvwuuQEHyFEY0mgn6NGrOMihBC1SKCfo0as4yKEELVIoJ+jRqzjIoQQtUignyNjLXQJdCFE40mgn6NEuiA9dCFEU5BAP0dGDV2mLAohGk8C/RyUSlpq6EKIpiGBfg4mcwW0lnVchBDNQQLd9FeP7+Uj9z7Hf33wJQrF0oz7pXIF7nr4FSYms8RTsjCXEKJ5SPHX9HdPHyRXLJErlPita9exPtJec78XD5/k/udeZ8vKMKs6/QD0hn0L2VQhhKhJeuiA1pqpXIEtK8MAxJKZGfe17huOJhiOxgEY6AvPfyOFEOI0JNCBdL6I1rCmKwDAeDI7474x876haJyh0QR9YR+dAc+CtFMIIWYjJRdgKlsEYE23EeixxCyBbt63+2iCk6k8A/3SOxdCNAfpoQNTWWMJ3BUhH16Xg/HJmQPdui+TL3Hw2BQDfaEFaaMQQpyOBDowlTMCPeB1EQl5iSVmqaEnMizzl2e1DEr9XAjRJCTQgVTOKLkEvE4iQZ9dJ69lPJll29pOvC7j0A30Sw9dCNEcJNCBSbPk4ve4iAS9xJJZDk9M8fF/2EEyk6/aN5bM0htu46IVQToDHlaEZMqiEKI5SKADKXNQtN3roifoZTyZ5QdDb/D4rjGeP3S8vF+uwGS2QE/Qyyfftp7Pbt+AUqpRzRZCiCoyy4XyoKjf4yQS9BJP53nx9RMADI8m+MWLlgPl6YyRoJd3DKxoTGOFEGIG0kOnPCja7nURCRollJ/umwCME4gsVm09ImUWIUQTkkCnPCjq9zrpCXmBcl19yDwbFMpz0CNB7wK3UAghTk8CHSO8XQ6Fx+mgp70c1lvPW8bIibS9CNe4edp/jwS6EKIJSaADqWyBgNeFUopIqBzWt1yxCsBesyWWzOJyKDr9cqq/EKL5SKADk9kiAY8TgK6AF4eC7nYP110UAcp19FgyS3e7F4dDZrYIIZqPzHLBmI4Y8BqHwulQdLd7uag3RFe7l76wz66jx5LZqh68EEI0Ewl0YCpXxO8tH4o/fPeAvcb5eV0BRk+kAWPaYn+HzHARQjQnKblgzEO3Si4AN13cy6WrlwHGAKi1INd4MiMDokKIpiWBjhno3tofViJBL7FElkKxxMRUjp6g9NCFEM1JAh3jxKLKHnqlSMhLOl/k0EQKrWUOuhCieUmgY6zlMnMP3eiRW1MXJdCFEM1KAh2zhz5DoFs1c2vqotTQhRDNak6BrpTarpTao5Tap5S6c5b9rlBKFZVSv1K/Js6vQrFEJl/CP1PJxQ50s4cu67gIIZrUaactKqWcwFeB64ER4Hml1CNa61019vsS8Nh8NLSevrPjCJ996GUA7rpxI2AszFWLVXIZGjV76O3SQxdCNKe59NC3Afu01ge01jngAeDmGvv9NvAQEKtj++bFT/bE6Ax46Wr38r1XjgLGxS1qCbW58LgcxNN5lvndeFxSpRJCNKe5pFM/cKTi9oi5zaaU6gfeC9w92wMppW5XSu1QSu0YHx8/07bWzXA0wZVrO7lybSdDo0YpJeCtXXJRStm98ohMWRRCNLG5BHqthUv0tNv/H/BZrXVxtgfSWt+jtd6qtd7a09Mz1zbWVSKT5/BEik19IQb6whRLxlMJzNBDB+zT/WVAVAjRzOZy6v8IsKri9kogOm2frcAD5uXYuoGblFIFrfW/1qWVdbTLnK0y2B+mco0t/ww9dCgPjMqURSFEM5tLoD8PXKCUWguMArcCt1XuoLVea32tlPom8L1mDHPALrEM9IVwVFwPdKZBUSj3zHtkYS4hRBM7baBrrQtKqU9hzF5xAvdqrYeVUneY989aN282w9EEK0I+us26eF/YRzSemXFQFMq1c6mhCyGa2ZxWW9RaPwo8Om1bzSDXWv/6uTdr/gxH4wz0hezbA/1hovHMjIOiICUXIcTi0PJz8KayBbZ84Yf85NUYuUKJfbFJNlUE+mazlh70uWd8jL6ONvN/6aELIZpXy6+HPp7MEk/n2TuWZKA/RElXn+350V9Yy+Vrls1aQ/+F9d3c++tbucxcUlcIIZpRywf6VK4AQDydJ5E2LvYcbiv3xtu9Lq5a1z3rYzgcil+8aPn8NVIIIeqg5UsuqZwxNT6RyRNPG+Ee8rX8+5gQYglq+UCfzFo99ELNHroQQrSKlg/0VNbsoafzJDJGoIck0IUQLajlA30qW66hx6WHLoRoYa0f6OagaCJTHhQNzTJFUQghFquWD3R7UNTsobe5nbIErhCiJbV8slmDool0gXg6T6hNZrgIIVpTywd6ygz0XLFELJmV+rkQomW1fKBPZstLtL9+PCX1cyFEy2r5QE+Zg6IAIyfS0kMXQrSslg/0qVy5h54rlGQOuhCiZbV+oGcLBCsW3pIeuhCiVS2JQO+tWPZW1nERQrSq1g/0XIHecJt9W0ouQohW1fKBnsoWWVGx/rkEuhCiVbV8oE/lCoT9bgIe4xJzUkMXQrSqlg70QrFEJl8i4HHZPXOZhy6EaFUtHeipvDFlMeB12j1z6aELIVpVSwe6tXSu3+Oye+aylosQolW1eKCXe+h2yUV66EKIFtWy3dVnD0zYy+QaNXQXDgXtnpZ9ykKIJa4l0+3A+CS33vMs7798JQABr4t1Pe2c39OOw6Ea3DohhJgfLRnooyfTAPxs/wRglFx+663r+Phbzm9ks4QQYl61ZKDHElmgHOx+jwuHQ+GR3rkQooW15KBoLJmtut3ubcn3LSGEqNKSgT4+LdD9XmeDWiKEEAunJQM9lszgqiiv+N0S6EKI1teigZ5l88owHpcDn9uBy9mST1MIIaq0ZHF5PJllU1+IfFETNQdGhRCi1bVsoEeCXtb3tLPzyMlGN0cIIRZEywV6KldgMlugJ+jlE9eub3RzhBBiwcypuKyU2q6U2qOU2qeUurPG/R9SSr1s/vuZUmpL/Zs6N9Yc9EjQd5o9hRCitZw20JVSTuCrwI3AJuCDSqlN03Y7CLxVa70Z+CJwT70bOlfjk1agexvVBCGEaIi59NC3Afu01ge01jngAeDmyh201j/TWp8wbz4LrKxvM+fO7qGHJNCFEEvLXAK9HzhScXvE3DaT3wC+X+sOpdTtSqkdSqkd4+Pjc2/lGYglMwD0tEugCyGWlrkEeq0FUHTNHZV6G0agf7bW/Vrre7TWW7XWW3t6eubeyjMQS2ZxORTL/J55eXwhhGhWc5nlMgKsqri9EohO30kptRn4BnCj1nqiPs07c+PJLD1BryyTK4RYcubSQ38euEAptVYp5QFuBR6p3EEptRp4GPhVrfXe+jdz7l6fSNHf0dbIJgghREOcNtC11gXgU8BjwG7gQa31sFLqDqXUHeZunwe6gK8ppXYqpXbMW4tnUSpphqNxBvpCjfjxQgjRUHM6sUhr/Sjw6LRtd1d8/THgY/Vt2pk7fDzFVK7IQF+40U0RQogF11KrVg2NxgEY6JceuhBi6WmpQB+OJnA7FRdEgo1uihBCLLgWC/Q4G1YE8bha6mkJIcSctEzyaa0ZjiYY6JX6uRBiaVp0gf7C4eP85rd3cDKVq9p+NJ7h+FSOQamfCyGWqEUX6FPZIo8Nj7ErmqjafujYFADrIu2NaJYQQjTcogt0a475UDRetT1mXhh6eUiWzRVCLE2LLtC72r30hn0MT+uhW4tyybK5QoilatEFOsBAX9iec26JJbL43A7avS13ESYhhJiTRRroIQ4cmyKVK9jbYskskaAPpWRRLiHE0rQoA32wP4zWsPtouexiXRhaCCGWqkUZ6NbAaGUdPZbMyFWKhBBL2qIM9N6wj86Ah7uf3M/HvmXMSY8ls3KVIiHEkrYoA10pxe3XnE9P0MsTu8d4YneMZKZARKYsCiGWsEUZ6AB3vHUdD97xZtxOxZN7YgD0SA1dCLGELdpAB/C6nFwQCfLUXuOC0xLoQoilbFEHOsBgf4hExpi+KLNchBBL2aIP9MqrE0WCUkMXQixdiz7QrdUVnQ5FZ8DT4NYIIUTjLPpAv2hFCKWgK+DB6ZCzRIUQS9eiX/gk4HVxfneANo+z0U0RQoiGWvSBDvCZGzagdaNbIYQQjdUSgb59sLfRTRBCiIZb9DV0IYQQBgl0IYRoERLoQgjRIiTQhRCiRUigCyFEi5BAF0KIFiGBLoQQLUICXQghWoTSDTrFUik1Dhw+i2/tBo7VuTn1IO06c83aNmnXmWnWdkHztu1c2nWe1rqn1h0NC/SzpZTaobXe2uh2TCftOnPN2jZp15lp1nZB87ZtvtolJRchhGgREuhCCNEiFmOg39PoBsxA2nXmmrVt0q4z06ztguZt27y0a9HV0IUQQtS2GHvoQgghapBAF0KIFrFoAl0ptV0ptUcptU8pdWeD27JKKfUTpdRupdSwUuo/m9v/UCk1qpTaaf67qQFtO6SUesX8+TvMbZ1KqceVUq+Z/y9b4DZtqDgmO5VSCaXU7zbieCml7lVKxZRSQxXbZjw+Sqm7zN+5PUqpGxrQtj9TSr2qlHpZKfUvSqkOc/sapVS64tjdvcDtmvG1W6hjNkO7/qmiTYeUUjvN7Qt5vGbKh/n/PdNaN/0/wAnsB84HPMBLwKYGtqcXuMz8OgjsBTYBfwh8usHH6hDQPW3bnwJ3ml/fCXypwa/lG8B5jThewDXAZcDQ6Y6P+Zq+BHiBtebvoHOB2/YOwGV+/aWKtq2p3K8Bx6zma7eQx6xWu6bd/xfA5xtwvGbKh3n/PVssPfRtwD6t9QGtdQ54ALi5UY3RWh/VWr9ofp0EdgP9jWrPHNwMfMv8+lvAexrYluuA/VrrszlL+JxprZ8Cjk/bPNPxuRl4QGud1VofBPZh/C4uWNu01j/UWhfMm88CK+fr559Ju2axYMdstnYppRRwC3D/fPzs2cySD/P+e7ZYAr0fOFJxe4QmCVCl1BrgUuA/zE2fMj8e37vQpQ2TBn6olHpBKXW7uW251vooGL9sQKQB7bLcSvUfWaOPF8x8fJrt9+4/Ad+vuL1WKfVzpdS/K6Xe0oD21HrtmuWYvQUY01q/VrFtwY/XtHyY99+zxRLoqsa2hs+3VEq1Aw8Bv6u1TgB/C6wDLgGOYnzkW2hXa60vA24EPqmUuqYBbahJKeUB3g18x9zUDMdrNk3ze6eU+hxQAP7R3HQUWK21vhT4L8B9SqnQAjZppteuWY7ZB6nuOCz48aqRDzPuWmPbWR2zxRLoI8CqitsrgWiD2gKAUsqN8WL9o9b6YQCt9ZjWuqi1LgFfZx4/ns9Eax01/48B/2K2YUwp1Wu2uxeILXS7TDcCL2qtx8w2Nvx4mWY6Pk3xe6eU+gjwS8CHtFl0NT+eT5hfv4BRd71wodo0y2vX8GOmlHIBvwz8k7VtoY9XrXxgAX7PFkugPw9coJRaa/bybgUeaVRjzPrc3wG7tdZ/WbG9t2K39wJD0793ntsVUEoFra8xBtSGMI7VR8zdPgJ8dyHbVaGq19To41VhpuPzCHCrUsqrlFoLXAA8t5ANU0ptBz4LvFtrnarY3qOUcppfn2+27cACtmum167hxwx4O/Cq1nrE2rCQx2umfGAhfs8WYtS3TiPHN2GMFu8HPtfgtvwCxkeil4Gd5r+bgG8Dr5jbHwF6F7hd52OMlr8EDFvHCegCfgS8Zv7f2YBj5gcmgHDFtgU/XhhvKEeBPEbP6DdmOz7A58zfuT3AjQ1o2z6M+qr1e3a3ue/7zNf4JeBF4F0L3K4ZX7uFOma12mVu/yZwx7R9F/J4zZQP8/57Jqf+CyFEi1gsJRchhBCnIYEuhBAtQgJdCCFahAS6EEK0CAl0IYRoERLoQgjRIiTQhRCiRfxf/+oc3Fo92lIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bot_1 = bot()\n",
    "bot_1.preprocessing_text(\"Híñ!4\")\n",
    "bot_1.preprocessing_example(\"hola chao\")\n",
    "\n",
    "bot_1.dataset(dataset)\n",
    "bot_1.dataset_check()\n",
    "bot_1.one_hot_encoding()\n",
    "bot_1.training(visualization=True)\n",
    "bot_1.save_model(\"name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e7d167b8bde7d7cf9a172b3e3477586a36da8945a7654fbe033faf78f7d94a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
